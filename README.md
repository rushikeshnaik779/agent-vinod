# agent-vinod

- In this repo I tried to work with the LLM models using Ollama as a server on which models are hosted. 
- Due to Computation constraints I am using small models which has really beginner understanding to the topics


- mlflow for the LLM/Agent evaluation 

https://mlflow.org/docs/latest/genai/eval-monitor/